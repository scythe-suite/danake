{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction The \u2202anake component is part of the scythe-suite and allows remote, authenticated, and isolated execution of a development environment. From the student point of view, \u2202anake is a web application: the authentication requires the student to upload a picture of her face, taken beside a photo ID; such picture will be obtained by using the widely supported MediaDevices Web API; the development environment is based on code-server , a \"version\" of Visual Studio Code that runs in the browser. The backend consists of a novel application handling the authentication (similar to \ud835\udf0f ) and a Docker swarm running a set of micro-services, accessible through a front facing Nginx reverse proxy.","title":"Introduction"},{"location":"auth/","text":"The Authentication Flow This document describes the authentication flow. The goal of the authentication in the context of the \u2202anake component is to link a student (identified by her email and a picture of her face, taken beside a photo ID) to an instance of the development environment she will use for the course of the exam; the purpose of the flow is to make as difficult as possible for every other student to connect to the same development environment, once the link is established. The first actor in the flow is the reverse proxy , it intercepts HTTP requests from the student and routes them according to various parameters to the authentication application (that collects student pictures) or to one of the instances of the code server . All these components live in a Docker swarm and networking among them is segregated from the Internet, the swarm has a single entry point (that is a URL). The reverse proxy (sitting at the entry point ) rules are: if the path starts with /da/ followed by a token (an alphanumeric string), the request will be routed to the authentication application , if the path starts with /cs/ (possibly followed by other parts), the request will be routed to one of the instances of the code server , according to the value of a routing cookie (if it corresponds to a known value); in every other case, an error page is returned. Tokens and cookies are cryptographically signed (using for instance itsdangerous ) so that their integrity can be checked and, moreover, they will be hard to guess. Every student gets her personal token (as part of a link to the \u2202anake entry point) by email before the beginning of the exam. The authentication application performs the following steps: whatever the request method is ( GET or POST ): if the token is invalid, it returns an error page; the token is used to derive the student identity (such as her name, for instance); if the student has already provided her picture, the application sends a redirect to the code server instance; if the request method is GET , the application sends a form requesting the student picture; if the request method is POST and the request contains a non-empty picture, the application tries to store atomically the picture. If it succeeds, it determines the routing cookie and sets it; in any case, it sends a redirect to itself. The above process (if every steps is preformed in a valid way) can be represented by the following diagram. sequenceDiagram participant T as Teacher participant S as Student participant A as Auth app participant C as Code server Note over T, S: via email T ->> S: sends token Note over S, C: via https S ->> A: sends token A -->> S: asks photo & id S ->> A: sends photo & id A -->> S: set cookie and redirect S ->> C: sends cookie It must be clear that, since sharing the routing cookie among students and third parties is not impossible, the present flow is quite weak : any client with the same cookie will be routed to the same development environment. As a form of mitigation, the reverse proxy requires a HTTPS connection and keeps a timed log of routing cookie and SSL Session ID pairs it handles (see RFC 246 for a description of the TLS Handshake and Session ID); this means that it will be very hard to conceal routing cookie sharing among different browsers. Another possible mitigation would be to restrict access to the code server from a single IP (the one of the first connection); given the instability of consumer networks (that moreover are often NAT-ed), this alternative seems less viable, even if more secure. The collected pictures will be used by a human verifier during the exam, or shortly after its end, to identify the students; immediately after the identification, the pictures can be discarded (for privacy compliance). Given that the routing cookie can only be obtained legally in the instant the picture is shot, the present flow ensures that, in case of cookie sharing, the identified student can not repudiate to have illegally offered her own credentials to a third person.","title":"The Authentication Flow"},{"location":"running/","text":"Deploying and Monitoring Two preliminary steps to run \u2202anake are: setup a Docker Swarm clustering environment, obtain SSL/TLS Certificates for the front facing web site \u2014 for example using Let's Encrypt . Such steps are quite standard (albeit complex), so are not described in detail here. The testing setup suggests a simple way to prepare a local environment to experiment before installing on dedicated servers. Contexts Observe that Docker Context are a very convenient way to refer to different environements; in particular, once a docker swarm has been setup and the host running the manager node has ssh access configured, a context referring to such swarm can be setup as docker context create --docker \"host=ssh://USER@HOST\" CONTEXT where USER and HOST are the credential for the manager host, and CONTEXT the name of the context; issuing docker context use CONTEXT will make all future docker commands refer to the manager host. To run the \u2202anake system, several services need to be deployed: the base stack providing the Portainer monitoring service, and a local Docker Registry required to provide, if needed, development images to all the other involved services; a danake stack providing the router and auth modules; a set of separate services providing an instance of the editor module per student. The first stack can be deployed without any further configuration issuing the command danake start base Once this stack is running, the command danake utils monitor can be run to open the monitoring site; the first connection will require to set a username and password that must be kept secret . To run the rest of the services, the auth module needs two configuration files, both placed in the confs directory: an auth-config.py file defining the following variables: SECRET_KEY , a random string that must be kept secret used by itsdangerous to sign tokens, TOKEN_DURATION and COOKIE_DURATION the expiration time for the token and cookie (in seconds). a uid2info.tsv (in tab separated format) containing a two-field line per student, the first field being the student ID number and the second any string useful to identify the student (for instance her first and last name). Before deploying other services, cookies need to be generated. The command danake utils cookies starting from the list in uid2info.tsv will generate the cookie2uid.map file (saved in the confs directory, that must be kept secret ) containing the association between cookies and student IDs used both by the auth module and the router one. Now the second stack and editor services can be deployed issuing danake start backend danake start editor To tear down the system, the correct sequence is danake stop editor danake stop backend danake stop base","title":"Deploying and Monitoring"},{"location":"testing/","text":"The development and testing environment To test and develop \u2202anake, the easiest way is to use Docker Machine to setup an environment based on a set of virtual machines. Once installed the tool and the dependencies (most notably VirtualBox ), just issue danake machine create danake machine setup to create the virtual machines and setup the swarm running on them; this step (unless the hosts are rebooted) need not be repeated; a very convenient way to use different setup is to use Docker Context . It is possible to create a danake-test context for this testing setup using danake machine context and switch to it as docker context danake-test The local registry # In production mode, \u2202anake pulls the images needed for the router , auth , editor and cli services from Docker Hub ; such images can be modified just by the project owner. Beside the permission issues, it will be very time consuming in any case to upload modified development images on a public registry; for this reason, the base stack runs a local registry that can be used to distribute development images to cluster members participating in the swarm. To use such registry, just set the global variable DANAKE_DEBUG to a non empty value, for instance as export DANAKE_DEBUG=1 Now, whenever some code or configuration in the modules directory is modified, just run danake images build danake images push to build the new images and upload them to the local registry; on the other hand, you can get the images with danake images pull Of course pushing to the official registry is restricted to the project owner.","title":"The development and testing environment"},{"location":"testing/#the-local-registry","text":"In production mode, \u2202anake pulls the images needed for the router , auth , editor and cli services from Docker Hub ; such images can be modified just by the project owner. Beside the permission issues, it will be very time consuming in any case to upload modified development images on a public registry; for this reason, the base stack runs a local registry that can be used to distribute development images to cluster members participating in the swarm. To use such registry, just set the global variable DANAKE_DEBUG to a non empty value, for instance as export DANAKE_DEBUG=1 Now, whenever some code or configuration in the modules directory is modified, just run danake images build danake images push to build the new images and upload them to the local registry; on the other hand, you can get the images with danake images pull Of course pushing to the official registry is restricted to the project owner.","title":"The local registry"}]}
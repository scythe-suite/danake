{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction # The \u2202anake component is part of the scythe-suite and allows remote, authenticated, and isolated execution of a development environment. From the student point of view, \u2202anake is a just web application : the authentication requires the student to upload a picture of her face, taken beside a photo ID; such picture will be obtained by using the widely supported MediaDevices Web API; the development environment is based on code-server , a \"version\" of Visual Studio Code that runs in the browser. The backend consists of a novel application handling the authentication (similar to \ud835\udf0f ) and a Docker swarm running a set of micro-services, accessible through a front facing Nginx reverse proxy.","title":"Introduction"},{"location":"auth/","text":"The Authentication Flow # The goal of the authentication in the context of the \u2202anake component is to link a student (identified by her email and possibly a picture of her face, taken beside a photo ID) to an instance of the development environment she will use for the course of the exam; the purpose of the flow is to make as difficult as possible for every other student to connect to the same development environment, once the link is established. The first actor in the flow is the router , it intercepts HTTP requests from the student and routes them according to various parameters to the authentication application (that possibly collects student pictures) or to one of the instances of the editor . All these components live in a Docker swarm and networking among them is segregated from the Internet, the swarm has a single entry point (that is a URL). The router (sitting at the entry point ) rules are: if the path starts with /da/ followed by a token (an alphanumeric string), the request will be routed to the authentication application , if the path starts with /cs/ (possibly followed by other parts), the request will be routed to one of the instances of the editor , according to the value of a routing cookie (if it corresponds to a known value); in every other case, an error page is returned. Tokens and cookies are cryptographically signed (using for instance itsdangerous ) so that their integrity can be checked and, moreover, they will be hard to guess. Every student gets her personal token (as part of a link to the \u2202anake entry point) by email before the beginning of the exam. The authentication application performs the following steps: whatever the request method is ( GET or POST ): if the token is invalid, it returns an error page; the token is used to derive the student identity (such as her name, for instance); if the student has already provided her picture, the application sends a redirect to the editor instance; if the request method is GET : if the student has been pre-authorized , it creates an empty picture placeholder and redirects her to the editor instance; else the application sends a form requesting the student picture; if the request method is POST and the request contains a non-empty picture, the application tries to store atomically the picture. If it succeeds, it determines the routing cookie and sets it; in any case, it sends a redirect to itself. The point of the pre-authorization is to let students take the exam in a class where there are no webcams available, but the teacher can ascertain their identities in some alternative way. The above process (if every steps is preformed in a valid way) can be represented by the following diagram (where the part about photos is absent in case of pre-authorization). sequenceDiagram participant T as Teacher participant S as Student participant A as Auth app participant E as Editor Note over T, S: via email T ->> S: sends token Note over S, E: via https S ->> A: sends token A -->> S: asks photo & id S ->> A: sends photo & id A -->> S: set cookie and redirect S ->> E: sends cookie It must be clear that, since sharing the routing cookie among students and third parties is not impossible, the present flow is quite weak : any client with the same cookie will be routed to the same development environment. As a form of mitigation, the router requires a HTTPS connection and keeps a timed log of routing cookie and SSL Session ID pairs it handles (see RFC 246 for a description of the TLS Handshake and Session ID); this means that it will be very hard to conceal routing cookie sharing among different browsers. Another possible mitigation would be to restrict access to the editor from a single IP (the one of the first connection); given the instability of consumer networks (that moreover are often NAT-ed), this alternative seems less viable, even if more secure. The collected pictures will be used by a human verifier during the exam, or shortly after its end, to identify the students; immediately after the identification, the pictures can be discarded (for privacy compliance). Given that the routing cookie can only be obtained legally in the instant the picture is shot, the present flow ensures that, in case of cookie sharing, the identified student can not repudiate to have illegally offered her own credentials to a third person.","title":"The Authentication Flow"},{"location":"mail/","text":"Mail merge # In order to communicate the tokens to the students (and to further allow to send personalized emails to them), \u2202anake provides a very simple authenticated mail merge web application. Such application allows to combine a tab separated list of student's email addresses (and possibly other information) with a templated text email and send it to the specified the students.","title":"Mail merge"},{"location":"running/","text":"Deploying and Monitoring # Two preliminary steps to run \u2202anake are: setup a Docker Swarm clustering environment, obtain SSL/TLS Certificates for the front facing web site \u2014 for example using Let's Encrypt . Such steps are quite standard (albeit complex), so are not described in detail here. The testing setup suggests a simple way to prepare a local environment to experiment before installing the clustering environment on dedicated servers. Contexts Observe that Docker Context are a very convenient way to refer to different environements; in particular, once a docker swarm has been setup and the host running the manager node has ssh access configured, a context referring to such swarm can be setup as docker context create --docker \"host=ssh://USER@HOST\" CONTEXT where USER and HOST are the credential for the manager host, and CONTEXT the name of the context; issuing docker context use CONTEXT will make all future docker commands refer to the manager host. To run the \u2202anake system, several services need to be deployed: the danake stack managing the router and auth services, plus Portainer monitoring service and it agents ; a set of separate services providing an instance of the editor module per student. To configure such services, first you need to setup some docker secrets and configs : the SSL/TLS Certificates (in the certs subdirecotry); an auth-config.py file defining the following variables: SECRET_KEY , a random string that must be kept secret used by itsdangerous to sign tokens, TOKEN_DURATION and COOKIE_DURATION the expiration time for the token and cookie (in seconds); a uid2info.tsv (in tab separated format) containing a two-field line per student, the first field being the student ID number and the second any string useful to identify the student (for instance her first and last name); the cookie2uid.map containing the association between cookies and student IDs. The last file is generated from uid2info.tsv and must be kept secret ; to generate it and and setup all the required configurations, just run danake config remove danake config create Once the setup has been completed, it is possible to run the stack with danake start danake and, once it is running, the command danake utils monitor can be run to open the monitoring service; the first connection will require to set a username and password that must be kept secret . If everything looks fine, the editor services can be deployed issuing danake start editor To tear down the system, the correct sequence is danake stop editor danake stop danake","title":"Deploying and Monitoring"},{"location":"testing/","text":"The development and testing environment # To test and develop \u2202anake, the easiest way is to use Docker Machine to setup an environment based on a set of virtual machines. Once installed the tool and the dependencies (most notably VirtualBox ), just issue danake machine create danake machine setup to create the virtual machines and setup the swarm running on them; this step (unless the hosts are rebooted) need not be repeated; a very convenient way to use different setup is to use Docker Context . It is possible to create a danake-test context for this testing setup using danake machine context and switch to it as docker context use danake-test The local registry # In production mode, \u2202anake pulls the images needed for the router , auth , editor and cli services from Docker Hub ; such images can be modified just by the project owner. Beside the permission issues, it will be very time consuming in any case to upload modified development images on a public registry; for this reason, the base stack runs a local registry that can be used to distribute development images to cluster members participating in the swarm. To use such registry, just set the global variable DANAKE_DEBUG to a non empty value in the danake-config.sh file as export DANAKE_DEBUG=1 and run the registry with danake start registry Now, whenever some code or configuration in the modules directory is modified, just run danake images build danake images push to build the new images and upload them to the local registry; on the other hand, you can get the images with danake images pull Of course pushing to the official registry is restricted to the project owner. At the end of the development cycle, just unset DANAKE_DEBUG and stop the registry with danake stop registry","title":"The development and testing environment"},{"location":"testing/#the-local-registry","text":"In production mode, \u2202anake pulls the images needed for the router , auth , editor and cli services from Docker Hub ; such images can be modified just by the project owner. Beside the permission issues, it will be very time consuming in any case to upload modified development images on a public registry; for this reason, the base stack runs a local registry that can be used to distribute development images to cluster members participating in the swarm. To use such registry, just set the global variable DANAKE_DEBUG to a non empty value in the danake-config.sh file as export DANAKE_DEBUG=1 and run the registry with danake start registry Now, whenever some code or configuration in the modules directory is modified, just run danake images build danake images push to build the new images and upload them to the local registry; on the other hand, you can get the images with danake images pull Of course pushing to the official registry is restricted to the project owner. At the end of the development cycle, just unset DANAKE_DEBUG and stop the registry with danake stop registry","title":"The local registry"}]}